{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from util import *\n",
    "\n",
    "import aesmc.model\n",
    "import aesmc.random_variable as rv\n",
    "import aesmc.state as st\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def one_hot(i, num_bins):\n",
    "    if isinstance(i, Variable):\n",
    "        return Variable(\n",
    "            torch.zeros(len(i), num_bins)\n",
    "        ).scatter_(1, i.long().unsqueeze(-1), 1)\n",
    "    else:\n",
    "        return torch.zeros(len(i), num_bins).scatter_(\n",
    "            1, i.long().unsqueeze(-1), 1\n",
    "        )\n",
    "    \n",
    "    \n",
    "class FlyInitialDistribution(aesmc.model.InitialDistribution):\n",
    "    def __init__(self, num_flies, num_actions, mental_state_dim):\n",
    "        self.num_flies = num_flies\n",
    "        self.num_actions = num_actions\n",
    "        self.mental_state_dim = mental_state_dim\n",
    "        \n",
    "        self.action_probabilities = Variable(torch.Tensor([1 / self.num_actions]).expand(self.num_actions))\n",
    "        self.position_mean = Variable(torch.zeros(2))\n",
    "        self.position_var = Variable(torch.ones(2)) # learn these values (either by hand or otherwise)\n",
    "        self.mental_state_mean = Variable(torch.zeros(mental_state_dim))\n",
    "        self.mental_state_var = Variable(torch.ones(mental_state_dim))\n",
    "    \n",
    "    def initial(self):\n",
    "        initial_state_random_variable = rv.StateRandomVariable()\n",
    "        for f in range(self.num_flies):\n",
    "            # Actions\n",
    "            initial_state_random_variable.set_random_variable_(\n",
    "                'action_{}'.format(f),\n",
    "                rv.Categorical(self.action_probabilities.unsqueeze(0).unsqueeze(0).expand(\n",
    "                    self.batch_size, self.num_particles, self.num_actions\n",
    "                ))\n",
    "            )\n",
    "            \n",
    "            # Positions\n",
    "            initial_state_random_variable.set_random_variable_(\n",
    "                'position_{}'.format(f),\n",
    "                rv.MultivariateIndependentNormal(\n",
    "                    self.position_mean.unsqueeze(0).unsqueeze(0).expand(\n",
    "                        self.batch_size, self.num_particles, 2\n",
    "                    ),\n",
    "                    self.position_var.unsqueeze(0).unsqueeze(0).expand(\n",
    "                        self.batch_size, self.num_particles, 2\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Mental states\n",
    "            initial_state_random_variable.set_random_variable_(\n",
    "                'mental_state_{}'.format(f),\n",
    "                rv.MultivariateIndependentNormal(\n",
    "                    self.mental_state_mean.unsqueeze(0).unsqueeze(0).expand(\n",
    "                        self.batch_size, self.num_particles, 2\n",
    "                    ),\n",
    "                    self.mental_state_var.unsqueeze(0).unsqueeze(0).expand(\n",
    "                        self.batch_size, self.num_particles, 2\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            \n",
    "class FlyTransitionNetwork(aesmc.model.TransitionNetwork):\n",
    "    def __init__(self, num_flies, num_actions, mental_state_dim):\n",
    "        super(FlyTransitionNetwork, self).__init__()\n",
    "        self.num_flies = num_flies\n",
    "        self.num_actions = num_actions\n",
    "        self.mental_state_dim = mental_state_dim\n",
    "        \n",
    "        # Action neural nets\n",
    "        hidden_layer_dim = 200\n",
    "        action_neural_nets = []\n",
    "        for _ in range(self.num_flies):\n",
    "            action_neural_nets.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(self.mental_state_dim, hidden_layer_dim),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hidden_layer_dim, hidden_layer_dim),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hidden_layer_dim, self.num_actions),\n",
    "                    nn.Softmax(dim=1)\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # Position neural nets\n",
    "        hidden_layer_dim = 200\n",
    "        position_neural_nets = []\n",
    "        for _ in range(self.num_flies):\n",
    "            position_neural_nets.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(self.mental_state_dim, hidden_layer_dim),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hidden_layer_dim, hidden_layer_dim),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hidden_layer_dim, 2)\n",
    "                )\n",
    "            )\n",
    "        self.position_var = Variable(torch.ones(2)) # learn these values (either by hand or otherwise)\n",
    "            \n",
    "        # Mental state neural nets\n",
    "        hidden_layer_dim = 200\n",
    "        mental_state_neural_nets = []\n",
    "        for _ in range(self.num_flies):\n",
    "            mental_state_neural_nets.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(self.mental_state_dim + 2, hidden_layer_dim),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hidden_layer_dim, hidden_layer_dim),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hidden_layer_dim, self.mental_state_dim)\n",
    "                )\n",
    "            )\n",
    "        self.mental_state_var = Variable(torch.ones(mental_state_dim))\n",
    "\n",
    "    def transition(self, previous_latent_state=None, time=None):\n",
    "        latent_state_random_variable = rv.StateRandomVariable()\n",
    "        for f in range(self.num_flies):\n",
    "            previous_action = previous_latent_state._values['action_{}'.format(f)]\n",
    "            previous_position = previous_latent_state._values['position_{}'.format(f)]\n",
    "            previous_mental_state = previous_latent_state._values['mental_state_{}'.format(f)]\n",
    "\n",
    "            # Action\n",
    "            latent_state_random_variable.set_random_variable_(\n",
    "                'action_{}'.format(f),\n",
    "                rv.Categorical(select_evaluate_scatter(\n",
    "                    previous_mental_state.view(-1, self.mental_state_dim),\n",
    "                    previous_action.view(-1),\n",
    "                    self.action_neural_nets,\n",
    "                    out_dim=self.num_actions\n",
    "                ).view(self.batch_size, self.num_particles, self.num_actions))\n",
    "            )\n",
    "            \n",
    "            # Position\n",
    "            latent_state_random_variable.set_random_variable_(\n",
    "                'position_{}'.format(f),\n",
    "                rv.MultivariateIndependentNormal(\n",
    "                    mean=select_evaluate_scatter(\n",
    "                        previous_mental_state.view(-1, self.mental_state_dim),\n",
    "                        previous_action.view(-1),\n",
    "                        self.position_neural_nets,\n",
    "                        out_dim=2\n",
    "                    ).view(self.batch_size, self.num_particles, 2),\n",
    "                    variance=self.position_var.unsqueeze(0).unsqueeze(0).expand(\n",
    "                        self.batch_size, self.num_particles, 2\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # Mental state\n",
    "            latent_state_random_variable.set_random_variable_(\n",
    "                'mental_state_{}'.format(f),\n",
    "                rv.MultivariateIndependentNormal(\n",
    "                    mean=select_evaluate_scatter(\n",
    "                        torch.cat(\n",
    "                            [\n",
    "                                previous_mental_state.view(-1, self.mental_state_dim),\n",
    "                                previous_position.view(-1, 2)\n",
    "                            ], dim=1\n",
    "                        ),\n",
    "                        previous_action.view(-1),\n",
    "                        self.mental_state_neural_nets,\n",
    "                        out_dim=self.mental_state_dim\n",
    "                    ).view(self.batch_size, self.num_particles, self.mental_state_dim),\n",
    "                    variance=self.mental_state_var.unsqueeze(0).unsqueeze(0).expand(\n",
    "                        self.batch_size, self.num_particles, self.mental_state_dim\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        return latent_state_random_variable\n",
    "    \n",
    "    \n",
    "class FlyEmissionNetwork(aesmc.model.EmissionNetwork):\n",
    "    def __init__(self, num_flies, mental_state_dim, num_encoding_bins):\n",
    "        self.num_flies = num_flies\n",
    "        self.mental_state_dim = mental_state_dim\n",
    "        self.num_encoding_bins = num_encoding_bins\n",
    "        self.position_sensor_var = Variable(torch.ones(2))\n",
    "        self.encoding_neural_net = nn.Sequential(\n",
    "            nn.Linear(self.mental_state_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, num_encoding_bins),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def emission(self, latent_state=None, time=None):\n",
    "        observation_state_random_variable = rv.StateRandomVariable()\n",
    "        for f in range(self.num_flies):\n",
    "            position = latent_state._values['position_{}'.format(f)]\n",
    "            mental_state = latent_state._values['mental_state_{}'.format(f)]\n",
    "            \n",
    "            # Position\n",
    "            observation_state_random_variable.set_random_variable_(\n",
    "                'observed_position_{}'.format(f),\n",
    "                rv.MultivariateIndependentNormal(\n",
    "                    mean=position,\n",
    "                    variance=self.position_sensor_var.unsqueeze(0).unsqueeze(0).expand(\n",
    "                        self.batch_size, self.num_particles, 2\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # Encoding\n",
    "            observation_state_random_variable.set_random_variable_(\n",
    "                'observed_encoding_{}'.format(f),\n",
    "                rv.MultivariateIndependentPseudobernoulli(\n",
    "                    self.encoding_neural_net(mental_state.view(-1, self.mental_state_dim)).view(\n",
    "                        self.batch_size, self.num_particles, self.num_encoding_bins\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        return observation_state_random_variable\n",
    "    \n",
    "    \n",
    "class FlyProposalNetwork(aesmc.model.ProposalNetwork):\n",
    "    def __init__(self, num_flies, num_actions, mental_state_dim, num_encoding_bins):\n",
    "        self.num_flies = num_flies\n",
    "        self.num_actions = num_actions\n",
    "        self.mental_state_dim = mental_state_dim\n",
    "        self.num_encoding_bins = num_encoding_bins\n",
    "        self.position_var = Variable(torch.ones(2))\n",
    "        \n",
    "        # Neural nets for time = 0\n",
    "        hidden_layer_dim = 200\n",
    "        self.initial_action_mlp = nn.Sequential(\n",
    "            nn.Linear(2 + self.num_encoding_bins, hidden_layer_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_layer_dim, hidden_layer_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_layer_dim, self.num_actions),\n",
    "            nn.Softmax(dim=1)\n",
    "        )        \n",
    "        self.initial_mental_state_mean_mlp = nn.Sequential(\n",
    "            nn.Linear(2 + self.num_encoding_bins, hidden_layer_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_layer_dim, hidden_layer_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_layer_dim, hidden_layer_dim)\n",
    "        )\n",
    "        self.initial_mental_state_var_mlp = nn.Sequential(\n",
    "            nn.Linear(2 + self.num_encoding_bins, hidden_layer_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_layer_dim, hidden_layer_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_layer_dim, hidden_layer_dim),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "        \n",
    "        # Neural nets for time > 0\n",
    "        self.action_mlp = nn.Sequential(\n",
    "            nn.Linear(self.num_actions + 2 + self.mental_state_dim + 2 + self.num_encoding_bins, hidden_layer_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_layer_dim, hidden_layer_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_layer_dim, self.num_actions),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        self.mental_state_mean_mlp = nn.Sequential(\n",
    "            nn.Linear(self.num_actions + 2 + self.mental_state_dim + 2 + self.num_encoding_bins, hidden_layer_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_layer_dim, hidden_layer_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_layer_dim, self.mental_state_dim)\n",
    "        )\n",
    "        self.mental_state_var_mlp = nn.Sequential(\n",
    "            nn.Linear(self.num_actions + 2 + self.mental_state_dim + 2 + self.num_encoding_bins, hidden_layer_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_layer_dim, hidden_layer_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_layer_dim, self.mental_state_dim),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "\n",
    "    def proposal(\n",
    "        self, previous_latent_state=None, time=None, observation_states=None\n",
    "    ):\n",
    "        latent_state_random_variable = rv.StateRandomVariable()\n",
    "        for f in range(self.num_flies):\n",
    "            observed_position = observation_states[time]._values['observed_position_{}'.format(f)]\n",
    "            observed_encoding = observation_states[time]._values['observed_encoding_{}'.format(f)]\n",
    "            \n",
    "            if time == 0:\n",
    "                # Action\n",
    "                latent_state_random_variable.set_random_variable_(\n",
    "                    'action_{}'.format(f),\n",
    "                    rv.Categorical(self.initial_action_mlp(\n",
    "                        torch.cat([\n",
    "                            observation_position.view(-1, 2), \n",
    "                            observation_encoding.view(-1, self.num_encoding_bins)\n",
    "                        ], dim=1)\n",
    "                    ).view(self.batch_size, self.num_particles, self.num_actions))\n",
    "                )\n",
    "\n",
    "                # Position\n",
    "                latent_state_random_variable.set_random_variable_(\n",
    "                    'position_{}'.format(f),\n",
    "                    rv.MultivariateIndependentNormal(\n",
    "                        mean=observed_position, # TODO: should we do something else here?\n",
    "                        variance=self.position_var.unsqueeze(0).unsqueeze(0).expand(\n",
    "                            self.batch_size, self.num_particles, 2\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                # Mental State\n",
    "                latent_state_random_variable.set_random_variable_(\n",
    "                    'mental_state_{}'.format(f),\n",
    "                    rv.MultivariateIndependentNormal(\n",
    "                        mean=self.initial_mental_state_mean_mlp(\n",
    "                            torch.cat([\n",
    "                                observation_position.view(-1, 2), \n",
    "                                observation_encoding.view(-1, self.num_encoding_bins)\n",
    "                            ], dim=1)\n",
    "                        ).view(self.batch_size, self.num_particles, -1),\n",
    "                        variance=self.initial_mental_state_var_mlp(\n",
    "                            torch.cat([\n",
    "                                observation_position.view(-1, 2), \n",
    "                                observation_encoding.view(-1, self.num_encoding_bins)\n",
    "                            ], dim=1)\n",
    "                        ).view(self.batch_size, self.num_particles, -1)\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                previous_action = previous_latent_state._values['action_{}'.format(f)]\n",
    "                previous_position = previous_latent_state._values['position_{}'.format(f)]\n",
    "                previous_mental_state = previous_latent_state._values['mental_state_{}'.format(f)]\n",
    "\n",
    "                # Action\n",
    "                latent_state_random_variable.set_random_variable_(\n",
    "                    'action_{}'.format(f),\n",
    "                    rv.Categorical(self.action_mlp(\n",
    "                        torch.cat([\n",
    "                            one_hot(previous_action.view(-1), self.num_actions),\n",
    "                            previous_position.view(-1, 2),\n",
    "                            previous_mental_state.view(-1, self.mental_state_dim),\n",
    "                            observation_position.view(-1, 2), \n",
    "                            observation_encoding.view(-1, self.num_encoding_bins)\n",
    "                        ], dim=1)\n",
    "                    ).view(self.batch_size, self.num_particles, self.num_actions))\n",
    "                )\n",
    "\n",
    "                # Position\n",
    "                latent_state_random_variable.set_random_variable_(\n",
    "                    'position_{}'.format(f),\n",
    "                    rv.MultivariateIndependentNormal(\n",
    "                        mean=observed_position, # TODO: should we do something else here?\n",
    "                        variance=self.position_var.unsqueeze(0).unsqueeze(0).expand(\n",
    "                            self.batch_size, self.num_particles, 2\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                # Mental State\n",
    "                latent_state_random_variable.set_random_variable_(\n",
    "                    'mental_state_{}'.format(f),\n",
    "                    rv.MultivariateIndependentNormal(\n",
    "                        mean=self.mental_state_mean_mlp(\n",
    "                            torch.cat([\n",
    "                                one_hot(previous_action.view(-1), self.num_actions),\n",
    "                                previous_position.view(-1, 2),\n",
    "                                previous_mental_state.view(-1, self.mental_state_dim),\n",
    "                                observation_position.view(-1, 2), \n",
    "                                observation_encoding.view(-1, self.num_encoding_bins)\n",
    "                            ], dim=1)\n",
    "                        ).view(self.batch_size, self.num_particles, -1),\n",
    "                        variance=self.mental_state_var_mlp(\n",
    "                            torch.cat([\n",
    "                                one_hot(previous_action.view(-1), self.num_actions),\n",
    "                                previous_position.view(-1, 2),\n",
    "                                previous_mental_state.view(-1, self.mental_state_dim),\n",
    "                                observation_position.view(-1, 2), \n",
    "                                observation_encoding.view(-1, self.num_encoding_bins)\n",
    "                            ], dim=1)\n",
    "                        ).view(self.batch_size, self.num_particles, -1)\n",
    "                    )\n",
    "                )\n",
    "        return latent_state_random_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
